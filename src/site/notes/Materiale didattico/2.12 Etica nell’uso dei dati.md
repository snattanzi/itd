---
{"dg-publish":true,"permalink":"/materiale-didattico/2-12-etica-nell-uso-dei-dati/"}
---


**Torna a [[Materiale didattico/2.11 Sistemi di rete\|2.11 Sistemi di rete]]**

---

Etica è quell’ambito di filosofia che si occupa di distinguere se i comportamenti umani siano giusti o sbagliati secondo un’ideale modello di comportamento, ovvero secondo una morale. In ambito di digitalizzazione e uso di dati la riflessione si pone sulla possibilità che a partire da dati si possano realizzare strumenti ingiusti, illeciti, sconvenienti, cattivi. Il carattere di convenienza legato all’utilizzo dei dati comunicato durante tutto il programma di formazione è attribuibile a tutto l’ambito di applicazioni oppure esiste un confine oltre il quale l’utilizzo dei dati può portare a generare soluzioni tecnologiche sconvenienti, cattive, illecite?

Nell’ambito di riferimento del presente corso di formazione, quello delle realtà industriali, si ricava difficilmente un esempio in tal senso: l’utilizzo di dati in azienda ha l’obiettivo di ricavare vantaggi in termini semplificazione e consapevolezza, concetti non riconducibili a temi morali per i quali si possa ritenerli sbagliati, cattivi. Rendere più semplice e consapevole il lavoro all’interno della propria azienda non può mai essere ritenuto illecito.

Per chiarire il motivo per cui questa tematica è presentata all’interno di questo programma di formazione si fornisce un esempio esplicativo, utile a concepire come sia rilevante in contesti diversi da quelli industriali.

Si può immaginare come ambito di applicazione di strumenti tecnologici digitali quello della politica. Immaginiamoci quindi che attraverso soluzioni di intelligenza artificiale vengano realizzati strumenti per ricavare considerazioni a supporto di scelte “consapevoli” di carattere politico. Questo genere di applicazioni non può, evidentemente, prescindere da considerazioni di carattere etico che prevedano interrogativi da porsi sulla liceità che si realizzino strumenti utili a suggerire decisioni che, necessariamente, favorirebbero alcuni a danno di altri.  L’impianto normativo che regola questi aspetti è attualmente basato sull’auto-regolamentazione. Immaginiamoci l’applicazione di algoritmi di intelligenza artificiale in campo di giustizia: è naturale ipotizzare che una logica imparziale non influenzabile da valutazioni esterne e che basi le proprie decisioni sui fatti/dati, sia un campo di applicazione ideale per la digitalizzazione. È dovuto però, in questo senso, porsi l’interrogativo se una giustizia così configurata sia necessariamente imparziale oppure questa valutazione sia frettolosa. Si dovesse ad esempio prevedere un’intelligenza in tema di giustizia predittiva, ovvero che basi le proprie decisioni su calcoli probabilistici utili alla formulazione di previsioni future, si ricaverebbero strumenti che attribuiscono profili di responsabilità a soggetti per effetto di azioni che questi realmente non hanno ancora compiuto.  Definire ciò che, a partire dall’analisi dei dati, è lecito realizzare, eticamente, è tema di attualità.

Nel 2017 il Consiglio europeo sottolineato l’urgenza di garantire un elevato livello di [protezione dei dati](https://www.altalex.com/documents/codici-altalex/2018/03/05/regolamento-generale-sulla-protezione-dei-dati-gdpr), diritti digitali e al tempo stesso norme etiche. Negli anni il Consiglio ha inoltre posto l'accento sull'importanza di garantire il pieno rispetto dei diritti dei cittadini europei esortando anche a rivedere la normativa pertinente in vigore con l'obiettivo di garantire che essa sia idonea allo scopo anche alla luce delle nuove opportunità e sfide poste dall'intelligenza artificiale, invitando inoltre a definire in maniera chiara quelle applicazioni di intelligenza artificiale che dovrebbero essere considerate ad alto rischio.  

Il 21 aprile 2021 è stata pubblicata dalla Commissione europea la “proposta di regolamento sull’approccio europeo all’Intelligenza Artificiale”, ovvero il primo quadro giuridico europeo sull’IA.  Tra le varie proposte contenute nel documento si ricavano, all’art.5, specifiche pratiche legate all’utilizzo dell’IA esplicitamente proibite e di seguito sintetizzate:

a) l'immissione sul mercato, la messa in servizio o l'uso di sistemi di IA che utilizzino tecniche subliminali al di là della consapevolezza di una persona al fine di falsare in misura rilevante il comportamento di una persona in modo tale da provocare o da poter causare a tale persona o ad un'altra persona un danno fisico o psicologico;

b) l'immissione sul mercato, la messa in servizio o l'uso di sistemi di IA che sfruttino qualsiasi vulnerabilità di un gruppo specifico di persone, per la loro età o disabilità fisica o mentale, al fine di falsarne in misura rilevante il comportamento in un modo che provochi o possa provocare danni fisici o psicologici agli stessi o ad altri;

c) l'immissione sul mercato, la messa in servizio o l'uso di sistemi di IA da parte di pubbliche autorità o per loro conto, che valuti o classifichi l'affidabilità delle persone fisiche per un determinato periodo di tempo sulla base del loro comportamento sociale o caratteristiche o della personalità, note o previste, mediante un punteggio sociale che determini uno o entrambi i seguenti elementi:

- un trattamento pregiudizievole o sfavorevole di talune persone fisiche o di interi gruppi di persone fisiche in contesti sociali che non hanno alcun rapporto con i contesti con cui i dati sono stati originariamente generati o raccolti;

- un trattamento pregiudizievole o sfavorevole di talune persone fisiche o  di interi gruppi di persone fisiche che sia sproporzionato rispetto alla gravità del loro comportamento sociale;

d) l'uso di sistemi di identificazione biometrica remota "in tempo reale" in spazi accessibili al pubblico ai fini dell'applicazione della legge, a meno che e nella misura in cui tale uso sia strettamente necessario per uno dei seguenti motivi:  

- la ricerca mirata di potenziali vittime di crimini, inclusi i bambini scomparsi;

- la prevenzione di specifiche e imminenti minacce alla vita di persone o di attacchi terroristici;

- l'accertamento, la localizzazione, l'identificazione o l'azione penale nei confronti di un autore del reato o sospettato di un reato punibile con una pena o una misura massima di almeno tre anni.

---

**prosegui a [[Materiale didattico/2.13 Privacy\|2.13 Privacy]]**

---

**Torna alla [[Home - ITD\|Home]]
